{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Importing Libraries**","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:19:49.221215Z","iopub.execute_input":"2022-08-20T10:19:49.221637Z","iopub.status.idle":"2022-08-20T10:19:49.236306Z","shell.execute_reply.started":"2022-08-20T10:19:49.221603Z","shell.execute_reply":"2022-08-20T10:19:49.235049Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\n#from flair.models import TextClassifier\n#from flair.data import Sentence\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport re\nimport string\nimport nltk\n'''\nnltk.download('stopwords')\nnltk.download('punkt')\nnltk.download('wordnet')\nnltk.download('averaged_perceptron_tagger')\nnltk.download('maxent_ne_chunker')\nnltk.download('words')\n'''\nfrom wordcloud import WordCloud\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer, PorterStemmer\nfrom nltk import pos_tag, ne_chunk\nfrom nltk.chunk import tree2conlltags\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:19:49.239727Z","iopub.execute_input":"2022-08-20T10:19:49.240603Z","iopub.status.idle":"2022-08-20T10:19:49.250158Z","shell.execute_reply.started":"2022-08-20T10:19:49.240554Z","shell.execute_reply":"2022-08-20T10:19:49.248939Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"****","metadata":{}},{"cell_type":"markdown","source":"**Importing Dataset**","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv('../input/firetvstick/final4k.csv', sep = ',')\ndf = data.copy()\ndata=data.dropna()\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:19:49.251407Z","iopub.execute_input":"2022-08-20T10:19:49.252331Z","iopub.status.idle":"2022-08-20T10:19:49.315872Z","shell.execute_reply.started":"2022-08-20T10:19:49.252279Z","shell.execute_reply":"2022-08-20T10:19:49.315067Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"**Cleaning The Dataset**","metadata":{}},{"cell_type":"code","source":"'''\nstop_words = set(stopwords.words(\"english\"))\ndf[\"Review\"] = df[\"Review\"].str.replace(\"\\d\",\"\")\n\ndef cleaner(data):\n    # Tokens\n    tokens = word_tokenize(str(data).replace(\"'\", \"\").lower())\n    # Remove Puncs\n    without_punc = [w for w in tokens if w.isalpha()]\n    # Stopwords\n    without_sw = [t for t in without_punc if t not in stop_words]\n    # Lemmatize\n    text_len = [WordNetLemmatizer().lemmatize(t) for t in without_sw]\n    # Stem\n    text_cleaned = [PorterStemmer().stem(w) for w in text_len]\n    return \" \".join(text_cleaned)\n\ndf[\"Review\"] = df[\"Review\"].apply(cleaner)\ndf[\"Review\"]\n'''\n'''\ndef remove_punctuation(text):\n    no_punct=[words for words in text if words not in string.punctuation]\n    words_wo_punct=''.join(no_punct)\n    return words_wo_punct\n\ndf['Review']=df['Review'].apply(lambda x: remove_punctuation(x))\n#df.head()\n\ndef tokenize(text):\n    split=re.split(\"\\W+\",text) \n    return split\n\ndf['Review']=df['Review'].apply(lambda x: tokenize(x.lower()))\n#df.head()\nstopword = nltk.corpus.stopwords.words('english')\nprint(stopword[:11])\n\ndef remove_stopwords(text):\n    text=[word for word in text if word not in stopword]\n    return text\ndf['Review'] = df['Review'].apply(lambda x: remove_stopwords(x))\n\ndf.head()\n'''","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:19:49.317207Z","iopub.execute_input":"2022-08-20T10:19:49.317739Z","iopub.status.idle":"2022-08-20T10:19:49.325023Z","shell.execute_reply.started":"2022-08-20T10:19:49.317707Z","shell.execute_reply":"2022-08-20T10:19:49.323912Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"**Assigning independent and dependent variables**","metadata":{}},{"cell_type":"code","source":"X=data['Review'].values\nY=data['flair_sentiment']\n#Y=data['Vader'].values\n#Y=data['TextBlob_Polarity'].values\n#Y=data['flair_sentiment'].values\n#Y = data['Suggestion/Complaint'].values\nprint(X.shape)\nprint(Y.shape)","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:19:49.328017Z","iopub.execute_input":"2022-08-20T10:19:49.329113Z","iopub.status.idle":"2022-08-20T10:19:49.345005Z","shell.execute_reply.started":"2022-08-20T10:19:49.329078Z","shell.execute_reply":"2022-08-20T10:19:49.343712Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"**Split the dataset/ Bag of Words**","metadata":{}},{"cell_type":"code","source":"X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.35)\nprint(X_train.shape,Y_train.shape)\nprint(X_test.shape,Y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:19:49.347581Z","iopub.execute_input":"2022-08-20T10:19:49.348127Z","iopub.status.idle":"2022-08-20T10:19:49.359227Z","shell.execute_reply.started":"2022-08-20T10:19:49.348081Z","shell.execute_reply":"2022-08-20T10:19:49.358019Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"**Apply Bag of words Features on Splitted data**","metadata":{}},{"cell_type":"code","source":"Vect=CountVectorizer()\nBow_train=Vect.fit_transform(X_train)\nBow_test=Vect.transform(X_test)\nprint(Bow_train.shape,Y_train.shape)\nprint(Bow_test.shape,Y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:19:49.361298Z","iopub.execute_input":"2022-08-20T10:19:49.361676Z","iopub.status.idle":"2022-08-20T10:19:49.477247Z","shell.execute_reply.started":"2022-08-20T10:19:49.361644Z","shell.execute_reply":"2022-08-20T10:19:49.476221Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"**Decision Tree and Training**","metadata":{}},{"cell_type":"code","source":"model=DecisionTreeClassifier(max_depth=6, class_weight='balanced')\n    \nmodel.fit(Bow_train, Y_train)\npredict=model.predict(Bow_test)\n\nconf_mat = confusion_matrix(Y_test, predict)\nclass_label = [\"Negative\", \"Positive\"]\ndf = pd.DataFrame(conf_mat, index = class_label, columns = class_label)\n    \nprint (\"Accuracy : \",accuracy_score(Y_test,predict)*100)\n\nreport=classification_report(Y_test,predict)\nprint(report)\n    \nsns.set()\nsns.heatmap(df, annot = True,fmt=\"d\")\nplt.title(\"Test_Confusion_Matrix\")\nplt.xlabel(\"Predicted_Label\")\nplt.ylabel(\"Actual_Label\")\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:19:49.478494Z","iopub.execute_input":"2022-08-20T10:19:49.479444Z","iopub.status.idle":"2022-08-20T10:19:49.831048Z","shell.execute_reply.started":"2022-08-20T10:19:49.479406Z","shell.execute_reply":"2022-08-20T10:19:49.829795Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"**Naive Bayes ML Algorithm**","metadata":{}},{"cell_type":"code","source":"sc = StandardScaler(with_mean=False)\nX_train_sc = sc.fit(Bow_train)\nX_Train = X_train_sc.transform(Bow_train)\nX_Test = X_train_sc.transform(Bow_test)\n\n# Training the Naive Bayes model on the Training set\nclassifier = GaussianNB()\nX_Train = X_Train.toarray()\nclassifier.fit(X_Train, Y_train)\n\n# Predicting the Test set results\nX_Test = X_Test.toarray()\ny_pred = classifier.predict(X_Test)\n\n# Making the Confusion Matrix\nac = accuracy_score(Y_test,y_pred)\ncm = confusion_matrix(Y_test, y_pred)\n\nclass_label = [\"Negative\", \"Positive\"]\ndf = pd.DataFrame(cm, index = class_label, columns = class_label)\n    \nprint (\"Accuracy : \",accuracy_score(Y_test, y_pred)*100)\n\nreport=classification_report(Y_test, y_pred)\nprint(report) \n    \nsns.set()\nsns.heatmap(df, annot = True,fmt=\"d\")\nplt.title(\"Test_Confusion_Matrix\")\nplt.xlabel(\"Predicted_Label\")\nplt.ylabel(\"Actual_Label\")\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:19:49.834090Z","iopub.execute_input":"2022-08-20T10:19:49.834493Z","iopub.status.idle":"2022-08-20T10:19:50.590650Z","shell.execute_reply.started":"2022-08-20T10:19:49.834459Z","shell.execute_reply":"2022-08-20T10:19:50.589449Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"**SVM Machine Learning Algorithm**","metadata":{}},{"cell_type":"code","source":"st_x= StandardScaler(with_mean=False)   \nx_train= st_x.fit_transform(Bow_train)    \nx_test= st_x.transform(Bow_test)\n\n#Training the SVM model\nclassifier = SVC(kernel='linear', random_state=0)  \nclassifier.fit(x_train, Y_train)\n\n#Predicting the Test results\ny_pred = classifier.predict(x_test)\n\n#Making the confusion matrix\nac = accuracy_score(Y_test,y_pred)\ncm= confusion_matrix(Y_test, y_pred)\n\nclass_label = [\"Negative\", \"Positive\"]\ndf = pd.DataFrame(cm, index = class_label, columns = class_label)\n\nprint (\"Accuracy : \",accuracy_score(Y_test, y_pred)*100)\n\nreport=classification_report(Y_test, y_pred)\nprint(report) \n    \nsns.set()\nsns.heatmap(df, annot = True,fmt=\"d\")\nplt.title(\"Test_Confusion_Matrix\")\nplt.xlabel(\"Predicted_Label\")\nplt.ylabel(\"Actual_Label\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:19:50.592397Z","iopub.execute_input":"2022-08-20T10:19:50.593037Z","iopub.status.idle":"2022-08-20T10:19:51.484928Z","shell.execute_reply.started":"2022-08-20T10:19:50.593001Z","shell.execute_reply":"2022-08-20T10:19:51.482341Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"**XG Boosting**","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBClassifier\n\nst_x= StandardScaler(with_mean=False)   \nx_train= st_x.fit_transform(Bow_train)    \nx_test= st_x.transform(Bow_test)\n\n\n# fit model no training data\nmodel = XGBClassifier()\nmodel.fit(x_train, Y_train)\n\n#Predicting the Test results\ny_pred = model.predict(x_test)\n\n#Making the confusion matrix\nac = accuracy_score(Y_test,y_pred)\ncm= confusion_matrix(Y_test, y_pred)\n\nclass_label = [\"Negative\", \"Positive\"]\ndf = pd.DataFrame(cm, index = class_label, columns = class_label)\n\nprint (\"Accuracy : \",accuracy_score(Y_test, y_pred)*100)\n\nreport=classification_report(Y_test, y_pred)\nprint(report) \n    \nsns.set()\nsns.heatmap(df, annot = True,fmt=\"d\")\nplt.title(\"Test_Confusion_Matrix\")\nplt.xlabel(\"Predicted_Label\")\nplt.ylabel(\"Actual_Label\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:19:51.488947Z","iopub.execute_input":"2022-08-20T10:19:51.489345Z","iopub.status.idle":"2022-08-20T10:19:52.690933Z","shell.execute_reply.started":"2022-08-20T10:19:51.489309Z","shell.execute_reply":"2022-08-20T10:19:52.689587Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"**Bag Of Words + XG Boosting**","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.model_selection import GridSearchCV\n\nst_x= StandardScaler(with_mean=False)   \nx_train= st_x.fit_transform(Bow_train)    \nx_test= st_x.transform(Bow_test)\n\nxgb = XGBClassifier()\nmodel = BaggingClassifier(base_estimator=xgb, n_estimators=31, random_state=314)\n# fit model to training data\nmodel.fit(x_train, Y_train)\n\n#Predicting the Test results\ny_pred = model.predict(x_test)\n\n#Making the confusion matrix\nac = accuracy_score(Y_test,y_pred)\ncm= confusion_matrix(Y_test, y_pred)\n\nclass_label = [\"Negative\", \"Positive\"]\ndf = pd.DataFrame(cm, index = class_label, columns = class_label)\n\nprint (\"Accuracy : \",accuracy_score(Y_test, y_pred)*100)\n\nreport=classification_report(Y_test, y_pred)\nprint(report) \n    \nsns.set()\nsns.heatmap(df, annot = True,fmt=\"d\")\nplt.title(\"Test_Confusion_Matrix\")\nplt.xlabel(\"Predicted_Label\")\nplt.ylabel(\"Actual_Label\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:19:52.692723Z","iopub.execute_input":"2022-08-20T10:19:52.693134Z","iopub.status.idle":"2022-08-20T10:20:18.273173Z","shell.execute_reply.started":"2022-08-20T10:19:52.693099Z","shell.execute_reply":"2022-08-20T10:20:18.271807Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"**Using Hyper Parameters on SVD Model**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n \n# defining parameter range\nparam_grid = {'C': [0.1, 1, 10, 100, 1000],\n              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n              'kernel': ['rbf']}\n \ngrid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)\n \n# fitting the model for grid search\ngrid.fit(x_train, Y_train)\n\ny_pred = grid.predict(x_test)\n \n#Making the confusion matrix\nac = accuracy_score(Y_test,y_pred)\ncm= confusion_matrix(Y_test, y_pred)\n\nclass_label = [\"Negative\", \"Positive\"]\ndf = pd.DataFrame(cm, index = class_label, columns = class_label)\n\nprint (\"Accuracy : \",accuracy_score(Y_test, y_pred)*100)\n\nreport=classification_report(Y_test, y_pred)\nprint(report) \n    \nsns.set()\nsns.heatmap(df, annot = True,fmt=\"d\")\nplt.title(\"Test_Confusion_Matrix\")\nplt.xlabel(\"Predicted_Label\")\nplt.ylabel(\"Actual_Label\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:20:18.275352Z","iopub.execute_input":"2022-08-20T10:20:18.276264Z","iopub.status.idle":"2022-08-20T10:22:47.205561Z","shell.execute_reply.started":"2022-08-20T10:20:18.276214Z","shell.execute_reply":"2022-08-20T10:22:47.204290Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"**Bagging On SVD**","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import LinearSVC\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.model_selection import GridSearchCV\n\n#import hasy_tools \n\n# Define model\n#svm = LinearSVC(random_state=42)\nsvm = SVC(kernel='linear', random_state=0) \nmodel = BaggingClassifier(base_estimator=svm, n_estimators=31, random_state=314)\n#dectree = DecisionTreeClassifier(max_depth=6, class_weight='balanced')\n#model = BaggingClassifier(base_estimator=dectree, n_estimators=31, random_state=314)\n# defining parameter range\n'''\nparam_grid = {'C': [0.1, 1, 10, 100, 1000],\n              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n              'kernel': ['rbf']}\n \ngrid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)\nmodel = BaggingClassifier(base_estimator=grid, n_estimators=3, random_state=314)\n'''\n\n# Fit\nmodel.fit(x_train, Y_train)\n\n#Prediction\ny_pred = model.predict(x_test)\n \n#Making the confusion matrix\nac = accuracy_score(Y_test,y_pred)\ncm= confusion_matrix(Y_test, y_pred)\n\nclass_label = [\"Negative\", \"Positive\"]\ndf = pd.DataFrame(cm, index = class_label, columns = class_label)\n\nprint (\"Accuracy : \",accuracy_score(Y_test, y_pred)*100)\n\nreport=classification_report(Y_test, y_pred)\nprint(report) \n    \nsns.set()\nsns.heatmap(df, annot = True,fmt=\"d\")\nplt.title(\"Test_Confusion_Matrix\")\nplt.xlabel(\"Predicted_Label\")\nplt.ylabel(\"Actual_Label\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-20T10:22:47.207527Z","iopub.execute_input":"2022-08-20T10:22:47.208481Z","iopub.status.idle":"2022-08-20T10:22:57.513833Z","shell.execute_reply.started":"2022-08-20T10:22:47.208436Z","shell.execute_reply":"2022-08-20T10:22:57.512663Z"},"trusted":true},"execution_count":19,"outputs":[]}]}